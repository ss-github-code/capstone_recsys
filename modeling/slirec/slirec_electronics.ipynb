{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short-term and Long-term preference Integrated RECommender system. (SLi_Rec)\n",
    "\n",
    "### SLi_Rec : Adaptive User Modeling with Long and Short-Term Preferences for Personailzed Recommendation\n",
    "Unlike a general recommender such as Matrix Factorization or xDeepFM which doesn't consider the order of the user's activities, sequential recommender systems take the sequence of the user behaviors as context and the goal is to predict the items that the user will interact in a short time (in an extreme case, the item that the user will interact next).\n",
    "\n",
    "SLi_Rec \\[1\\] is a deep learning-based model aims at capturing both long and short-term user preferences for precise recommender systems. To summarize, SLi_Rec has the following key properties:\n",
    "\n",
    "* It adopts the attentive \"Asymmetric-SVD\" paradigm for long-term modeling;\n",
    "* It takes both time irregularity and semantic irregularity into consideration by modifying the gating logic in LSTM.\n",
    "* It uses an attention mechanism to dynamically fuse the long-term component and short-term component.\n",
    "\n",
    "In this notebook, we test SLi_Rec on a subset of the public dataset: [Amazon_reviews] which includes all categories related to Electronics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/shiv/Documents/DataScience/Kaggle/recommenders/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.9.12 (main, Apr  5 2022, 06:56:58) \n",
      "[GCC 7.5.0]\n",
      "Tensorflow version: 2.8.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import papermill as pm\n",
    "import scrapbook as sb\n",
    "from tempfile import TemporaryDirectory\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.get_logger().setLevel('ERROR') # only show error messages\n",
    "\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.utils.constants import SEED\n",
    "from recommenders.models.deeprec.deeprec_utils import (\n",
    "    prepare_hparams\n",
    ")\n",
    "\n",
    "from recommenders.models.deeprec.models.sequential.sli_rec import SLI_RECModel as SeqModel\n",
    "from recommenders.models.deeprec.io.sequential_iterator import SequentialIterator\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Tensorflow version: {}\".format(tf.__version__))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 400\n",
    "RANDOM_SEED = SEED  # Set None for non-deterministic result\n",
    "\n",
    "DATA_DIR_WIDE_DEEP = '/home/shiv/Documents/DataScience/Capstone/Data/wide_deep/' # for top k predictions\n",
    "yaml_file = '../../recommenders/models/deeprec/config/sli_rec.yaml'  \n",
    "data_path = '/home/shiv/Documents/DataScience/Capstone/Data/slirec/Electronics'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SLi-Rec\n",
    "The SLi_Rec model is <b>time-aware</b>.\n",
    "\n",
    "We use Softmax to the loss function. In training and evalution stage, we group 1 positive instance with `num_ngs` negative instances. Pair-wise ranking can be regarded as a special case of softmax ranking, where `num_ngs` is set to 1. \n",
    "\n",
    "More specifically, for training and evalation, we need to organize the data file such that each <b>one positive instance</b> is followed by <b>`num_ngs` negative instances</b>. \n",
    "\n",
    "The program will take `1+num_ngs` lines as a unit for Softmax calculation. `num_ngs` is a parameter you need to pass to the `prepare_hparams`, `fit` and `run_eval` function. `train_num_ngs` in `prepare_hparams` denotes the number of negative instances for training, where a recommended number is 4. `valid_num_ngs` and `num_ngs` in `fit` and `run_eval` denote the number in evalution. In evaluation, the model calculates metrics among the `1+num_ngs` instances. For the `predict` function, since we only need to calcuate a score for each individual instance, there is no need for `num_ngs` setting.\n",
    "\n",
    "For training stage, we don't have to prepare negative instances, we can just provide positive instances and set the parameter `need_sample=True, train_num_ngs=train_num_ngs` for function `prepare_hparams`, our model will dynamicly sample `train_num_ngs` instances as negative samples in each mini batch.\n",
    "\n",
    "###  Amazon dataset\n",
    "Now let's start with a public dataset containing product reviews and metadata from Amazon, which is widely used as a benchmark dataset in recommemdation systems field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_vocab = os.path.join(data_path, r'user_vocab.pkl')\n",
    "item_vocab = os.path.join(data_path, r'item_vocab.pkl')\n",
    "cate_vocab = os.path.join(data_path, r'category_vocab.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = os.path.join(data_path, r'train_data')\n",
    "valid_file = os.path.join(data_path, r'valid_data')\n",
    "test_file = os.path.join(data_path, r'test_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare hyper-parameters\n",
    "prepare_hparams() will create a full set of hyper-parameters for model training, such as learning rate, feature number, and dropout ratio. We can put those parameters in a yaml file (a complete list of parameters can be found under our config folder) , or pass parameters as the function's parameters (which will overwrite yaml settings).\n",
    "\n",
    "Parameters hints: <br>\n",
    "`need_sample` controls whether to perform dynamic negative sampling in mini-batch. \n",
    "`train_num_ngs` indicates how many negative instances followed by one positive instances.  <br>\n",
    "Examples: <br>\n",
    "(1) `need_sample=True and train_num_ngs=4`:  There are only positive instances in your training file. Our model will dynamically sample 4 negative instances for each positive instances in mini-batch. Note that if need_sample is set to True, train_num_ngs should be greater than zero. <br>\n",
    "(2) `need_sample=False and train_num_ngs=4`: In your training file, each one positive line is followed by 4 negative lines. Note that if need_sample is set to False, you must provide a traiing file with negative instances, and train_num_ngs should match the number of negative number in your training file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters\n",
    "- learning_rate=0.001\n",
    "- dropout=0.3\n",
    "- item_embedding_dim=32\n",
    "- cate_embedding_dim=8\n",
    "- l2_norm=0\n",
    "- batch_size=400\n",
    "- train_num_ngs=4, valid_num_ngs=4, test_num_ngs=49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TRAIN_NUM_NEGS = 4\n",
    "VALID_NUM_NEGS = 4\n",
    "TEST_NUM_NEGS = 49\n",
    "hparams = prepare_hparams(yaml_file, \n",
    "                          embed_l2=0., \n",
    "                          layer_l2=0., \n",
    "                          learning_rate=0.001,  # set to 0.01 if batch normalization is disable\n",
    "                          epochs=EPOCHS,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          show_step=1000,\n",
    "                          MODEL_DIR=os.path.join(data_path, \"model/\"),\n",
    "                          SUMMARIES_DIR=os.path.join(data_path, \"summary/\"),\n",
    "                          user_vocab=user_vocab,\n",
    "                          item_vocab=item_vocab,\n",
    "                          cate_vocab=cate_vocab,\n",
    "                          need_sample=True,\n",
    "                          train_num_ngs=TRAIN_NUM_NEGS, # provides the number of negative instances for each positive instance for loss computation.\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HParams object with values {'use_entity': True, 'use_context': True, 'cross_activation': 'identity', 'user_dropout': True, 'dropout': [0.3, 0.3], 'attention_dropout': 0.0, 'load_saved_model': False, 'fast_CIN_d': 0, 'use_Linear_part': False, 'use_FM_part': False, 'use_CIN_part': False, 'use_DNN_part': False, 'init_method': 'tnormal', 'init_value': 0.01, 'embed_l2': 0.0, 'embed_l1': 0.0, 'layer_l2': 0.0, 'layer_l1': 0.0, 'cross_l2': 0.0, 'cross_l1': 0.0, 'reg_kg': 0.0, 'learning_rate': 0.001, 'lr_rs': 1, 'lr_kg': 0.5, 'kg_training_interval': 5, 'max_grad_norm': 2, 'is_clip_norm': 0, 'dtype': 32, 'optimizer': 'adam', 'epochs': 10, 'batch_size': 400, 'enable_BN': True, 'show_step': 1000, 'save_model': True, 'save_epoch': 1, 'write_tfevents': True, 'train_num_ngs': 4, 'need_sample': True, 'embedding_dropout': 0.0, 'EARLY_STOP': 10, 'min_seq_length': 1, 'slots': 5, 'cell': 'SUM', 'user_vocab': '/home/shiv/Documents/DataScience/Capstone/Data/slirec/Electronics/user_vocab.pkl', 'item_vocab': '/home/shiv/Documents/DataScience/Capstone/Data/slirec/Electronics/item_vocab.pkl', 'cate_vocab': '/home/shiv/Documents/DataScience/Capstone/Data/slirec/Electronics/category_vocab.pkl', 'method': 'classification', 'model_type': 'sli_rec', 'layer_sizes': [100, 64], 'att_fcn_layer_sizes': [80, 40], 'activation': ['relu', 'relu'], 'item_embedding_dim': 32, 'cate_embedding_dim': 8, 'user_embedding_dim': 16, 'loss': 'softmax', 'max_seq_length': 50, 'hidden_size': 40, 'attention_size': 40, 'metrics': ['auc', 'logloss'], 'pairwise_metrics': ['mean_mrr', 'ndcg@2;4;6', 'group_auc'], 'MODEL_DIR': '/home/shiv/Documents/DataScience/Capstone/Data/slirec/Electronics/model/', 'SUMMARIES_DIR': '/home/shiv/Documents/DataScience/Capstone/Data/slirec/Electronics/summary/'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create data loader\n",
    "Designate a data iterator for the model. All our sequential models use SequentialIterator. \n",
    "\n",
    "Validation and testing data are files after negative sampling offline with the number of `<num_ngs>` and `<test_num_ngs>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_creator = SequentialIterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Jump to Model Serving](#model_serving) if we already have a pre-built model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model\n",
    "When both hyper-parameters and data iterator are ready, we can create a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shiv/Documents/DataScience/Kaggle/recommenders/recommenders/models/deeprec/models/base_model.py:701: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  curr_hidden_nn_layer = tf.compat.v1.layers.batch_normalization(\n",
      "/home/shiv/anaconda3/envs/RecSys_39/lib/python3.9/site-packages/keras/legacy_tf_layers/normalization.py:463: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs, training=training)\n",
      "2022-08-10 14:56:01.827427: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-10 14:56:02.389622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5650 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-08-10 14:56:02.390139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 6113 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:04:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "model = SeqModel(hparams, input_creator, seed=RANDOM_SEED)\n",
    "\n",
    "## sometimes we don't want to train a model from scratch\n",
    "## then we can load a pre-trained model like this: \n",
    "#model.load_model(r'your_model_path')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see what is the model's performance at this point (without starting training):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-10 15:02:31.150186: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'auc': 0.5046, 'logloss': 0.6931, 'mean_mrr': 0.0943, 'ndcg@2': 0.0377, 'ndcg@4': 0.0571, 'ndcg@6': 0.0715, 'group_auc': 0.5048}\n"
     ]
    }
   ],
   "source": [
    "# test_num_ngs is the number of negative lines after each positive line in your test_file\n",
    "print(model.run_eval(test_file, num_ngs=TEST_NUM_NEGS))\n",
    "\n",
    "# {'auc': 0.5046, 'logloss': 0.6931, 'mean_mrr': 0.0943, 'ndcg@2': 0.0377, 'ndcg@4': 0.0571, 'ndcg@6': 0.0715, 'group_auc': 0.5048}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC=0.5 is a state of random guess. We can see that before training, the model behaves like random guessing.\n",
    "\n",
    "#### Train model\n",
    "Next we want to train the model on a training set, and check the performance on a validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1000 , total_loss: 1.3674, data_loss: 1.3674\n",
      "step 2000 , total_loss: 1.2056, data_loss: 1.2056\n",
      "step 3000 , total_loss: 1.1830, data_loss: 1.1830\n",
      "step 4000 , total_loss: 1.0902, data_loss: 1.0902\n",
      "step 5000 , total_loss: 1.1233, data_loss: 1.1233\n",
      "step 6000 , total_loss: 1.1259, data_loss: 1.1259\n",
      "step 7000 , total_loss: 1.0653, data_loss: 1.0653\n",
      "step 8000 , total_loss: 1.0380, data_loss: 1.0380\n",
      "eval valid at epoch 1: auc:0.7958,logloss:0.8247,mean_mrr:0.7191,ndcg@2:0.6818,ndcg@4:0.7772,ndcg@6:0.7898,group_auc:0.7917\n",
      "step 1000 , total_loss: 0.9902, data_loss: 0.9902\n",
      "step 2000 , total_loss: 0.9667, data_loss: 0.9667\n",
      "step 3000 , total_loss: 0.9465, data_loss: 0.9465\n",
      "step 4000 , total_loss: 0.9676, data_loss: 0.9676\n",
      "step 5000 , total_loss: 0.8955, data_loss: 0.8955\n",
      "step 6000 , total_loss: 0.9343, data_loss: 0.9343\n",
      "step 7000 , total_loss: 0.8669, data_loss: 0.8669\n",
      "step 8000 , total_loss: 0.9591, data_loss: 0.9591\n",
      "eval valid at epoch 2: auc:0.8134,logloss:1.1699,mean_mrr:0.7403,ndcg@2:0.7081,ndcg@4:0.7951,ndcg@6:0.8057,group_auc:0.8101\n",
      "step 1000 , total_loss: 0.9328, data_loss: 0.9328\n",
      "step 2000 , total_loss: 1.0547, data_loss: 1.0547\n",
      "step 3000 , total_loss: 0.9174, data_loss: 0.9174\n",
      "step 4000 , total_loss: 0.9464, data_loss: 0.9464\n",
      "step 5000 , total_loss: 0.9057, data_loss: 0.9057\n",
      "step 6000 , total_loss: 0.8531, data_loss: 0.8531\n",
      "step 7000 , total_loss: 0.8641, data_loss: 0.8641\n",
      "step 8000 , total_loss: 0.9510, data_loss: 0.9510\n",
      "eval valid at epoch 3: auc:0.8203,logloss:1.5644,mean_mrr:0.7496,ndcg@2:0.7197,ndcg@4:0.8027,ndcg@6:0.8128,group_auc:0.8176\n",
      "step 1000 , total_loss: 0.8997, data_loss: 0.8997\n",
      "step 2000 , total_loss: 0.9222, data_loss: 0.9222\n",
      "step 3000 , total_loss: 0.8456, data_loss: 0.8456\n",
      "step 4000 , total_loss: 0.8470, data_loss: 0.8470\n",
      "step 5000 , total_loss: 0.9609, data_loss: 0.9609\n",
      "step 6000 , total_loss: 0.9113, data_loss: 0.9113\n",
      "step 7000 , total_loss: 0.8801, data_loss: 0.8801\n",
      "step 8000 , total_loss: 0.9260, data_loss: 0.9260\n",
      "eval valid at epoch 4: auc:0.8247,logloss:2.0349,mean_mrr:0.7538,ndcg@2:0.725,ndcg@4:0.8062,ndcg@6:0.8159,group_auc:0.8213\n",
      "step 1000 , total_loss: 0.8109, data_loss: 0.8109\n",
      "step 2000 , total_loss: 0.9117, data_loss: 0.9117\n",
      "step 3000 , total_loss: 0.8796, data_loss: 0.8796\n",
      "step 4000 , total_loss: 0.9421, data_loss: 0.9421\n",
      "step 5000 , total_loss: 0.8512, data_loss: 0.8512\n",
      "step 6000 , total_loss: 0.8980, data_loss: 0.8980\n",
      "step 7000 , total_loss: 0.9389, data_loss: 0.9389\n",
      "step 8000 , total_loss: 0.8954, data_loss: 0.8954\n",
      "eval valid at epoch 5: auc:0.8242,logloss:2.4964,mean_mrr:0.7545,ndcg@2:0.7253,ndcg@4:0.8064,ndcg@6:0.8164,group_auc:0.8211\n",
      "step 1000 , total_loss: 0.7658, data_loss: 0.7658\n",
      "step 2000 , total_loss: 0.8145, data_loss: 0.8145\n",
      "step 3000 , total_loss: 0.8100, data_loss: 0.8100\n",
      "step 4000 , total_loss: 0.8978, data_loss: 0.8978\n",
      "step 5000 , total_loss: 0.7944, data_loss: 0.7944\n",
      "step 6000 , total_loss: 0.7909, data_loss: 0.7909\n",
      "step 7000 , total_loss: 0.7754, data_loss: 0.7754\n",
      "step 8000 , total_loss: 0.8180, data_loss: 0.8180\n",
      "eval valid at epoch 6: auc:0.825,logloss:2.862,mean_mrr:0.7574,ndcg@2:0.7292,ndcg@4:0.8089,ndcg@6:0.8186,group_auc:0.8238\n",
      "step 1000 , total_loss: 0.7822, data_loss: 0.7822\n",
      "step 2000 , total_loss: 0.8537, data_loss: 0.8537\n",
      "step 3000 , total_loss: 0.7926, data_loss: 0.7926\n",
      "step 4000 , total_loss: 0.8098, data_loss: 0.8098\n",
      "step 5000 , total_loss: 0.8628, data_loss: 0.8628\n",
      "step 6000 , total_loss: 0.8452, data_loss: 0.8452\n",
      "step 7000 , total_loss: 0.8466, data_loss: 0.8466\n",
      "step 8000 , total_loss: 0.7964, data_loss: 0.7964\n",
      "eval valid at epoch 7: auc:0.8262,logloss:3.2406,mean_mrr:0.7583,ndcg@2:0.7298,ndcg@4:0.8094,ndcg@6:0.8192,group_auc:0.8242\n",
      "step 1000 , total_loss: 0.8084, data_loss: 0.8084\n",
      "step 2000 , total_loss: 0.7809, data_loss: 0.7809\n",
      "step 3000 , total_loss: 0.8087, data_loss: 0.8087\n",
      "step 4000 , total_loss: 0.7483, data_loss: 0.7483\n",
      "step 5000 , total_loss: 0.8459, data_loss: 0.8459\n",
      "step 6000 , total_loss: 0.8936, data_loss: 0.8936\n",
      "step 7000 , total_loss: 0.9160, data_loss: 0.9160\n",
      "step 8000 , total_loss: 0.8860, data_loss: 0.8860\n",
      "eval valid at epoch 8: auc:0.8252,logloss:3.7278,mean_mrr:0.7579,ndcg@2:0.7294,ndcg@4:0.8092,ndcg@6:0.8189,group_auc:0.824\n",
      "step 1000 , total_loss: 0.8493, data_loss: 0.8493\n",
      "step 2000 , total_loss: 0.8123, data_loss: 0.8123\n",
      "step 3000 , total_loss: 0.7614, data_loss: 0.7614\n",
      "step 4000 , total_loss: 0.7611, data_loss: 0.7611\n",
      "step 5000 , total_loss: 0.7498, data_loss: 0.7498\n",
      "step 6000 , total_loss: 0.8642, data_loss: 0.8642\n",
      "step 7000 , total_loss: 0.8486, data_loss: 0.8486\n",
      "step 8000 , total_loss: 0.7694, data_loss: 0.7694\n",
      "eval valid at epoch 9: auc:0.825,logloss:4.0868,mean_mrr:0.7578,ndcg@2:0.7291,ndcg@4:0.809,ndcg@6:0.8189,group_auc:0.8236\n",
      "step 1000 , total_loss: 0.7159, data_loss: 0.7159\n",
      "step 2000 , total_loss: 0.7140, data_loss: 0.7140\n",
      "step 3000 , total_loss: 0.8318, data_loss: 0.8318\n",
      "step 4000 , total_loss: 0.7224, data_loss: 0.7224\n",
      "step 5000 , total_loss: 0.7762, data_loss: 0.7762\n",
      "step 6000 , total_loss: 0.9121, data_loss: 0.9121\n",
      "step 7000 , total_loss: 0.8016, data_loss: 0.8016\n",
      "step 8000 , total_loss: 0.7965, data_loss: 0.7965\n",
      "eval valid at epoch 10: auc:0.8248,logloss:4.4202,mean_mrr:0.7582,ndcg@2:0.7296,ndcg@4:0.8094,ndcg@6:0.8192,group_auc:0.824\n",
      "[(1, {'auc': 0.7958, 'logloss': 0.8247, 'mean_mrr': 0.7191, 'ndcg@2': 0.6818, 'ndcg@4': 0.7772, 'ndcg@6': 0.7898, 'group_auc': 0.7917}), (2, {'auc': 0.8134, 'logloss': 1.1699, 'mean_mrr': 0.7403, 'ndcg@2': 0.7081, 'ndcg@4': 0.7951, 'ndcg@6': 0.8057, 'group_auc': 0.8101}), (3, {'auc': 0.8203, 'logloss': 1.5644, 'mean_mrr': 0.7496, 'ndcg@2': 0.7197, 'ndcg@4': 0.8027, 'ndcg@6': 0.8128, 'group_auc': 0.8176}), (4, {'auc': 0.8247, 'logloss': 2.0349, 'mean_mrr': 0.7538, 'ndcg@2': 0.725, 'ndcg@4': 0.8062, 'ndcg@6': 0.8159, 'group_auc': 0.8213}), (5, {'auc': 0.8242, 'logloss': 2.4964, 'mean_mrr': 0.7545, 'ndcg@2': 0.7253, 'ndcg@4': 0.8064, 'ndcg@6': 0.8164, 'group_auc': 0.8211}), (6, {'auc': 0.825, 'logloss': 2.862, 'mean_mrr': 0.7574, 'ndcg@2': 0.7292, 'ndcg@4': 0.8089, 'ndcg@6': 0.8186, 'group_auc': 0.8238}), (7, {'auc': 0.8262, 'logloss': 3.2406, 'mean_mrr': 0.7583, 'ndcg@2': 0.7298, 'ndcg@4': 0.8094, 'ndcg@6': 0.8192, 'group_auc': 0.8242}), (8, {'auc': 0.8252, 'logloss': 3.7278, 'mean_mrr': 0.7579, 'ndcg@2': 0.7294, 'ndcg@4': 0.8092, 'ndcg@6': 0.8189, 'group_auc': 0.824}), (9, {'auc': 0.825, 'logloss': 4.0868, 'mean_mrr': 0.7578, 'ndcg@2': 0.7291, 'ndcg@4': 0.809, 'ndcg@6': 0.8189, 'group_auc': 0.8236}), (10, {'auc': 0.8248, 'logloss': 4.4202, 'mean_mrr': 0.7582, 'ndcg@2': 0.7296, 'ndcg@4': 0.8094, 'ndcg@6': 0.8192, 'group_auc': 0.824})]\n",
      "best epoch: 7\n",
      "Time cost for training is 253.59 mins\n"
     ]
    }
   ],
   "source": [
    "with Timer() as train_time:\n",
    "    model = model.fit(train_file, valid_file, valid_num_ngs=VALID_NUM_NEGS) \n",
    "\n",
    "# valid_num_ngs is the number of negative lines after each positive line in your valid_file \n",
    "# we will evaluate the performance of model on valid_file every epoch\n",
    "print('Time cost for training is {0:.2f} mins'.format(train_time.interval/60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from recommenders.utils import plot\n",
    "\n",
    "valid_auc = [0.7958, 0.8134, 0.8203, 0.8247, 0.8242, 0.825, 0.8262, 0.8252, 0.825, 0.8248]\n",
    "\n",
    "x = range(1,11)\n",
    "plot.line_graph(\n",
    "    values=valid_auc,\n",
    "    labels='valid',\n",
    "    x_name='epochs',\n",
    "    y_name='auc',\n",
    "    legend_loc='lower right'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate model\n",
    "\n",
    "Again, let's see what is the model's performance now (after training):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'auc': 0.8225, 'logloss': 5.4335, 'mean_mrr': 0.3525, 'ndcg@2': 0.2748, 'ndcg@4': 0.3369, 'ndcg@6': 0.372, 'group_auc': 0.8232}\n"
     ]
    }
   ],
   "source": [
    "res_syn = model.run_eval(test_file, num_ngs=TEST_NUM_NEGS)\n",
    "print(res_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.glue(\"res_syn\", res_syn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to get the full prediction scores rather than evaluation metrics, we can do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_file = os.path.join(data_path, r'output.txt')\n",
    "# model = model.predict(test_file, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model_serving\"></a>\n",
    "## Model Serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shiv/Documents/DataScience/Kaggle/recommenders/recommenders/models/deeprec/models/base_model.py:701: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  curr_hidden_nn_layer = tf.compat.v1.layers.batch_normalization(\n",
      "/home/shiv/anaconda3/envs/RecSys_39/lib/python3.9/site-packages/keras/legacy_tf_layers/normalization.py:463: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs, training=training)\n",
      "2022-08-10 20:35:57.005443: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-10 20:35:57.977279: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5654 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-08-10 20:35:57.978378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 6113 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:04:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading saved model in /home/shiv/Documents/DataScience/Capstone/Data/slirec/Electronics/model/best_model\n"
     ]
    }
   ],
   "source": [
    "model_best_trained = SeqModel(hparams, input_creator, seed=RANDOM_SEED)\n",
    "path_best_trained = os.path.join(hparams.MODEL_DIR, \"best_model\")\n",
    "\n",
    "print('loading saved model in {0}'.format(path_best_trained))\n",
    "model_best_trained.load_model(path_best_trained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we load the model correctly by running evaluation on a test file. The testing metrics should be better than what we had at the end of training where we did not load the best model. You can also [jump to predicting topK for a user](#topK)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-10 20:42:41.645548: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'auc': 0.8242,\n",
       " 'logloss': 3.9834,\n",
       " 'mean_mrr': 0.352,\n",
       " 'ndcg@2': 0.2738,\n",
       " 'ndcg@4': 0.3361,\n",
       " 'ndcg@6': 0.3714,\n",
       " 'group_auc': 0.8238}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Note: auc: 0.8242 as compared to 0.8225 from the model at the end of epoch 10\n",
    "model_best_trained.run_eval(test_file, num_ngs=TEST_NUM_NEGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can make predictions using the best model. Then we can check if the metrics from run_eval match with those received from predict function which only outputs prediction scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<recommenders.models.deeprec.models.sequential.sli_rec.SLI_RECModel at 0x7f47d41d6760>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file = os.path.join(data_path, r'output.txt')\n",
    "model_best_trained.predict(test_file, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for consistent results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8241692825299073 3.983422418807104\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (roc_auc_score, log_loss)\n",
    "\n",
    "# Gather the true labels\n",
    "true_labels = []\n",
    "with open(test_file, 'r') as f:\n",
    "    for line in f:\n",
    "        parts = line.split('\\t')\n",
    "        true_labels.append(float(parts[0]))\n",
    "# Gather the predictions\n",
    "preds = []\n",
    "with open(output_file, 'r') as f:\n",
    "    for line in f:\n",
    "        preds.append(float(line))\n",
    "print(roc_auc_score(true_labels, preds), log_loss(true_labels, preds))\n",
    "# The ROC auc and logloss match!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_mrr': 0.352,\n",
       " 'ndcg@2': 0.2738,\n",
       " 'ndcg@4': 0.3361,\n",
       " 'ndcg@6': 0.3714,\n",
       " 'ndcg@10': 0.4128,\n",
       " 'group_auc': 0.8238}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from recommenders.models.deeprec.deeprec_utils import cal_metric\n",
    "\n",
    "# Pairwise metrics\n",
    "group = TEST_NUM_NEGS + 1\n",
    "\n",
    "group_labels = np.reshape(true_labels, (-1, group))\n",
    "group_preds = np.reshape(preds, (-1, group))\n",
    "\n",
    "cal_metric(group_labels, group_preds, ['mean_mrr', 'ndcg@2;4;6;10', 'group_auc'])\n",
    "# And the pairwise metrics match too! We have ndcg@10 too!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"topK\"></a>\n",
    "### TopK prediction for a user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as cPickle\n",
    "\n",
    "with open(user_vocab, 'rb') as f:\n",
    "    u_v = cPickle.load(f)test_\n",
    "with open(item_vocab, 'rb') as f:\n",
    "    v_v = cPickle.load(f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(497252, 63715)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(u_v), len(v_v) # only 497252 users in train (out of 830668), and 63715 items (out of 63725)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userID        \n",
       "ANGGNFE8DXGYC     324\n",
       "ARBKYIVNYWK3C     243\n",
       "A1H2WJSALF3E9U    238\n",
       "A31N0XY2UTB25C    236\n",
       "A1XXMNLOLKNO0I    232\n",
       "                 ... \n",
       "A2WY5PH4O5CDW       1\n",
       "A2WY5K9Z5KTF7M      1\n",
       "A2WY50O1L0XMPD      1\n",
       "A2WY4NSVFD6PO3      1\n",
       "A1LCYW5S3IKKKM      1\n",
       "Length: 830668, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Get the userID who has the most reviews\n",
    "prep_df = pd.read_csv(data_path + '/preprocessed.output', sep='\\t', header=None)\n",
    "prep_df.columns = ['type', 'label', 'userID', 'itemID', 'ts', 'category']\n",
    "prep_df[['userID']].value_counts() # Note that we have 830668 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63725"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_df['itemID'].nunique() # Note that we have 63725 items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>label</th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>ts</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72789</th>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>ANGGNFE8DXGYC</td>\n",
       "      <td>B013JZCAZK</td>\n",
       "      <td>2018-03-25</td>\n",
       "      <td>Computers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72788</th>\n",
       "      <td>valid</td>\n",
       "      <td>1</td>\n",
       "      <td>ANGGNFE8DXGYC</td>\n",
       "      <td>B00IXN6L3G</td>\n",
       "      <td>2018-03-25</td>\n",
       "      <td>All Electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72787</th>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>ANGGNFE8DXGYC</td>\n",
       "      <td>B00609B3J2</td>\n",
       "      <td>2018-03-25</td>\n",
       "      <td>Home Audio &amp; Theater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72786</th>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>ANGGNFE8DXGYC</td>\n",
       "      <td>B00505EZYW</td>\n",
       "      <td>2018-03-25</td>\n",
       "      <td>All Electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72785</th>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>ANGGNFE8DXGYC</td>\n",
       "      <td>B000AO7SJW</td>\n",
       "      <td>2018-03-25</td>\n",
       "      <td>All Electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72497</th>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>ANGGNFE8DXGYC</td>\n",
       "      <td>B008ALA6DW</td>\n",
       "      <td>2015-06-26</td>\n",
       "      <td>Computers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72496</th>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>ANGGNFE8DXGYC</td>\n",
       "      <td>B0082ZJNW6</td>\n",
       "      <td>2015-06-26</td>\n",
       "      <td>Home Audio &amp; Theater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72495</th>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>ANGGNFE8DXGYC</td>\n",
       "      <td>B007I59CN6</td>\n",
       "      <td>2015-06-26</td>\n",
       "      <td>Computers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72494</th>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>ANGGNFE8DXGYC</td>\n",
       "      <td>B006ZGCH18</td>\n",
       "      <td>2015-06-26</td>\n",
       "      <td>Computers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72466</th>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>ANGGNFE8DXGYC</td>\n",
       "      <td>B000KGLL84</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>Car Electronics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>324 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        type  label         userID      itemID         ts  \\\n",
       "72789   test      1  ANGGNFE8DXGYC  B013JZCAZK 2018-03-25   \n",
       "72788  valid      1  ANGGNFE8DXGYC  B00IXN6L3G 2018-03-25   \n",
       "72787  train      1  ANGGNFE8DXGYC  B00609B3J2 2018-03-25   \n",
       "72786  train      1  ANGGNFE8DXGYC  B00505EZYW 2018-03-25   \n",
       "72785  train      1  ANGGNFE8DXGYC  B000AO7SJW 2018-03-25   \n",
       "...      ...    ...            ...         ...        ...   \n",
       "72497  train      1  ANGGNFE8DXGYC  B008ALA6DW 2015-06-26   \n",
       "72496  train      1  ANGGNFE8DXGYC  B0082ZJNW6 2015-06-26   \n",
       "72495  train      1  ANGGNFE8DXGYC  B007I59CN6 2015-06-26   \n",
       "72494  train      1  ANGGNFE8DXGYC  B006ZGCH18 2015-06-26   \n",
       "72466  train      1  ANGGNFE8DXGYC  B000KGLL84 2010-02-05   \n",
       "\n",
       "                   category  \n",
       "72789             Computers  \n",
       "72788       All Electronics  \n",
       "72787  Home Audio & Theater  \n",
       "72786       All Electronics  \n",
       "72785       All Electronics  \n",
       "...                     ...  \n",
       "72497             Computers  \n",
       "72496  Home Audio & Theater  \n",
       "72495             Computers  \n",
       "72494             Computers  \n",
       "72466       Car Electronics  \n",
       "\n",
       "[324 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user = 'ANGGNFE8DXGYC'\n",
    "\n",
    "u_df = prep_df[prep_df['userID']==user].copy()\n",
    "u_df['ts'] = pd.to_datetime(u_df['ts'],unit='s')\n",
    "u_df.sort_values(['ts'], inplace=True, ascending=False)\n",
    "u_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308\n"
     ]
    }
   ],
   "source": [
    "items_seen = u_df[u_df['type']!='test']['itemID'].unique()\n",
    "print(len(items_seen))\n",
    "\n",
    "all_items_set = set(prep_df['itemID'].unique())\n",
    "items_not_seen = list(all_items_set - set(items_seen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the row from the test file for the user 'ANGGNFE8DXGYC'\n",
    "test_df = pd.read_csv(test_file, sep='\\t', header=None)\n",
    "test_df.columns=['label', 'userID', 'itemID', 'category', 'ts', 'lst_items', 'lst_category', 'lst_ts']\n",
    "test_df = test_df[test_df['userID'] == user]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tmp_dir = TemporaryDirectory()\n",
    "\n",
    "# we only need itemID->category\n",
    "prep_df = prep_df[['itemID', 'category']]\n",
    "prep_df.drop_duplicates(inplace=True)\n",
    "prep_df.set_index('itemID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63417/63417 [00:02<00:00, 26087.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a test file with all the unseen items\n",
    "tst_file = tmp_dir.name + '/tst_file'\n",
    "out = open(tst_file, 'w')\n",
    "\n",
    "# print(tst_file)\n",
    "for item in tqdm(items_not_seen):\n",
    "    if item.startswith('default'):\n",
    "        continue\n",
    "    lst = []\n",
    "    lst.append('1')  # fake label: unused\n",
    "    lst.append(user) # user\n",
    "    lst.append(item) # unseen item\n",
    "    lst.append(prep_df.loc[item]['category'])\n",
    "    \n",
    "    lst.append(str(test_df['ts'].values[0])) # timestamp and history remains the same as the first of 50 rows\n",
    "    lst.append(test_df['lst_items'].values[0])\n",
    "    lst.append(test_df['lst_category'].values[0])\n",
    "    lst.append(test_df['lst_ts'].values[0])\n",
    "\n",
    "    entry = '\\t'.join(lst) + '\\n'\n",
    "    out.write(entry)\n",
    "\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model's predict function takes in an input test file and outputs prediction scores\n",
    "output_file = os.path.join(tmp_dir.name, r'output.txt')\n",
    "model_best_trained.predict(tst_file, output_file)\n",
    "\n",
    "# now create a result dataframe along with scores\n",
    "res_df = pd.read_csv(tst_file, sep='\\t', header=None)\n",
    "res_df.columns = ['label', 'userID', 'itemID', 'category', 'ts', 'lst_items', 'lst_cate', 'lst_ts']\n",
    "res_df = res_df[['itemID', 'category']]\n",
    "tmp_df = pd.read_csv(output_file, header=None)\n",
    "tmp_df.columns = ['score']\n",
    "res_df['score'] = tmp_df['score']\n",
    "\n",
    "res_df.sort_values(['score'], ascending=False, inplace=True)\n",
    "res_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>215594</th>\n",
       "      <td>B001584R6E</td>\n",
       "      <td>Power Acoustik BAMF4000/1D 1200W Class D Mono ...</td>\n",
       "      <td>Electronics|Car &amp; Vehicle Electronics|Marine E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>B000BUBJ9A</td>\n",
       "      <td>Hanes Short Sleeve 6 oz Tagless T-Shirt with P...</td>\n",
       "      <td>Clothing, Shoes &amp; Jewelry|Men|Clothing|Shirts|...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              asin                                              title  \\\n",
       "215594  B001584R6E  Power Acoustik BAMF4000/1D 1200W Class D Mono ...   \n",
       "1231    B000BUBJ9A  Hanes Short Sleeve 6 oz Tagless T-Shirt with P...   \n",
       "\n",
       "                                                 category  \n",
       "215594  Electronics|Car & Vehicle Electronics|Marine E...  \n",
       "1231    Clothing, Shoes & Jewelry|Men|Clothing|Shirts|...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_df = pd.read_csv(DATA_DIR_WIDE_DEEP + 'all_meta_20.csv', header=None)\n",
    "items_df.columns=['asin','price','title','main_cat','category']\n",
    "items_df = items_df[['asin','title','category']]\n",
    "items_df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>246366</th>\n",
       "      <td>B013JZCAZK</td>\n",
       "      <td>New iPad 9.7\" (2018 &amp; 2017) / iPad Pro 9.7 / i...</td>\n",
       "      <td>Electronics|Computers &amp; Accessories|Tablet Acc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              asin                                              title  \\\n",
       "246366  B013JZCAZK  New iPad 9.7\" (2018 & 2017) / iPad Pro 9.7 / i...   \n",
       "\n",
       "                                                 category  \n",
       "246366  Electronics|Computers & Accessories|Tablet Acc...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_item_clicked = test_df.iloc[0]['itemID']\n",
    "items_df[items_df['asin'] == actual_item_clicked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_x</th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "      <th>category_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Computers</td>\n",
       "      <td>0.999899</td>\n",
       "      <td>Monoprice SlimRun Cat6A Ethernet Patch Cable -...</td>\n",
       "      <td>Electronics|Computers &amp; Accessories|Computer A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Computers</td>\n",
       "      <td>0.999894</td>\n",
       "      <td>10Gtek for Cisco GLC-EX-SMD, Gigabit SFP EX Tr...</td>\n",
       "      <td>Electronics|Computers &amp; Accessories|Networking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home Audio &amp; Theater</td>\n",
       "      <td>0.999889</td>\n",
       "      <td>Edifier S1000DB Audiophile Active Bookshelf Sp...</td>\n",
       "      <td>Electronics|Home Audio|Speakers|Bookshelf Spea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All Electronics</td>\n",
       "      <td>0.999886</td>\n",
       "      <td>AmazonBasics Component Video Cable with Audio ...</td>\n",
       "      <td>Electronics|Accessories &amp; Supplies|Audio &amp; Vid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Computers</td>\n",
       "      <td>0.999886</td>\n",
       "      <td>Ubiquiti Unifi Security Gateway (USG)</td>\n",
       "      <td>Electronics|Computers &amp; Accessories|Networking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Home Audio &amp; Theater</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>Cable Matters (5-Pack) Gold-Plated RG6 Keyston...</td>\n",
       "      <td>Electronics|Accessories &amp; Supplies|Audio &amp; Vid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Home Audio &amp; Theater</td>\n",
       "      <td>0.999881</td>\n",
       "      <td>THE CIMPLE CO - Dual, Twin, or Siamese Coaxial...</td>\n",
       "      <td>Electronics|Accessories &amp; Supplies|Cord Manage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Computers</td>\n",
       "      <td>0.999866</td>\n",
       "      <td>Cable Matters 10-Pack Snagless Cat6 Ethernet C...</td>\n",
       "      <td>Electronics|Computers &amp; Accessories|Computer A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Computers</td>\n",
       "      <td>0.999864</td>\n",
       "      <td>UGREEN RJ45 Coupler 5 Pack In Line Coupler Cat...</td>\n",
       "      <td>Electronics|Computers &amp; Accessories|Computer A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Computers</td>\n",
       "      <td>0.999864</td>\n",
       "      <td>AmazonBasics RJ45 Cat7 Network Ethernet Patch ...</td>\n",
       "      <td>Electronics|Computers &amp; Accessories|Computer A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category_x     score  \\\n",
       "0             Computers  0.999899   \n",
       "1             Computers  0.999894   \n",
       "2  Home Audio & Theater  0.999889   \n",
       "3       All Electronics  0.999886   \n",
       "4             Computers  0.999886   \n",
       "5  Home Audio & Theater  0.999885   \n",
       "6  Home Audio & Theater  0.999881   \n",
       "7             Computers  0.999866   \n",
       "8             Computers  0.999864   \n",
       "9             Computers  0.999864   \n",
       "\n",
       "                                               title  \\\n",
       "0  Monoprice SlimRun Cat6A Ethernet Patch Cable -...   \n",
       "1  10Gtek for Cisco GLC-EX-SMD, Gigabit SFP EX Tr...   \n",
       "2  Edifier S1000DB Audiophile Active Bookshelf Sp...   \n",
       "3  AmazonBasics Component Video Cable with Audio ...   \n",
       "4              Ubiquiti Unifi Security Gateway (USG)   \n",
       "5  Cable Matters (5-Pack) Gold-Plated RG6 Keyston...   \n",
       "6  THE CIMPLE CO - Dual, Twin, or Siamese Coaxial...   \n",
       "7  Cable Matters 10-Pack Snagless Cat6 Ethernet C...   \n",
       "8  UGREEN RJ45 Coupler 5 Pack In Line Coupler Cat...   \n",
       "9  AmazonBasics RJ45 Cat7 Network Ethernet Patch ...   \n",
       "\n",
       "                                          category_y  \n",
       "0  Electronics|Computers & Accessories|Computer A...  \n",
       "1  Electronics|Computers & Accessories|Networking...  \n",
       "2  Electronics|Home Audio|Speakers|Bookshelf Spea...  \n",
       "3  Electronics|Accessories & Supplies|Audio & Vid...  \n",
       "4  Electronics|Computers & Accessories|Networking...  \n",
       "5  Electronics|Accessories & Supplies|Audio & Vid...  \n",
       "6  Electronics|Accessories & Supplies|Cord Manage...  \n",
       "7  Electronics|Computers & Accessories|Computer A...  \n",
       "8  Electronics|Computers & Accessories|Computer A...  \n",
       "9  Electronics|Computers & Accessories|Computer A...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_merged = res_df.merge(items_df, left_on='itemID', right_on='asin')\n",
    "res_merged.drop(columns=['itemID', 'asin'], inplace=True)\n",
    "res_merged.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemID</th>\n",
       "      <th>category_x</th>\n",
       "      <th>score</th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "      <th>category_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>B013JZCAZK</td>\n",
       "      <td>Computers</td>\n",
       "      <td>0.998656</td>\n",
       "      <td>B013JZCAZK</td>\n",
       "      <td>New iPad 9.7\" (2018 &amp; 2017) / iPad Pro 9.7 / i...</td>\n",
       "      <td>Electronics|Computers &amp; Accessories|Tablet Acc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          itemID category_x     score        asin  \\\n",
       "2999  B013JZCAZK  Computers  0.998656  B013JZCAZK   \n",
       "\n",
       "                                                  title  \\\n",
       "2999  New iPad 9.7\" (2018 & 2017) / iPad Pro 9.7 / i...   \n",
       "\n",
       "                                             category_y  \n",
       "2999  Electronics|Computers & Accessories|Tablet Acc...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_merged = res_df.merge(items_df, left_on='itemID', right_on='asin')\n",
    "res_merged[res_merged['asin']=='B013JZCAZK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_merged.drop(columns=['itemID', 'asin'], inplace=True)\n",
    "res_merged.to_csv(data_path + '/output_8009.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\\[1\\] Zeping Yu, Jianxun Lian, Ahmad Mahmoody, Gongshen Liu, Xing Xie. Adaptive User Modeling with Long and Short-Term Preferences for Personailzed Recommendation. In Proceedings of the 28th International Joint Conferences on Artificial Intelligence, IJCAI19, Pages 4213-4219. AAAI Press, 2019.\n",
    "\n",
    "\\[2\\] Balzs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, Domonkos Tikk. Session-based Recommendations with Recurrent Neural Networks. ICLR (Poster) 2016\n",
    "\n",
    "\\[3\\] Tang, Jiaxi, and Ke Wang. Personalized top-n sequential recommendation via convolutional sequence embedding. Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining. ACM, 2018.\n",
    "\n",
    "\\[4\\] Yuan, F., Karatzoglou, A., Arapakis, I., Jose, J. M., & He, X. A Simple Convolutional Generative Network for Next Item Recommendation. WSDM, 2019\n",
    "\n",
    "\\[5\\] Lian, J., Batal, I., Liu, Z., Soni, A., Kang, E. Y., Wang, Y., & Xie, X. Multi-Interest-Aware User Modeling for Large-Scale Sequential Recommendations. (2021) arXiv preprint arXiv:2102.09211."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "interpreter": {
   "hash": "3a9a0c422ff9f08d62211b9648017c63b0a26d2c935edc37ebb8453675d13bb5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
